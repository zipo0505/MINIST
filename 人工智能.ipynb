{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zipo0505/MNIST/blob/main/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "zwFnJsE6vjf8"
      },
      "outputs": [],
      "source": [
        "\n",
        "from torch import nn\n",
        "\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "        \t\t\t\t\t\tnn.Conv2d(1,16,kernel_size=3) ,\n",
        "                                nn.BatchNorm2d(16) ,\n",
        "                                nn.ReLU(inplace=True))\n",
        "\n",
        "        self.layer2 = nn.Sequential(\n",
        "        \t\t\t\t\t\tnn.Conv2d(16,32,kernel_size=3) ,\n",
        "                                nn.BatchNorm2d(32) ,\n",
        "                                nn.ReLU(inplace=True) ,\n",
        "                                nn.MaxPool2d(kernel_size=2 , stride=2))\n",
        "\n",
        "        self.layer3 = nn.Sequential(\n",
        "        \t\t\t\t\t\tnn.Conv2d(32,64,kernel_size=3) ,\n",
        "                                nn.BatchNorm2d(64) ,\n",
        "                                nn.ReLU(inplace=True))\n",
        "\n",
        "        self.layer4 = nn.Sequential(\n",
        "        \t\t\t\t\t\tnn.Conv2d(64,128,kernel_size=3) ,\n",
        "                                nn.BatchNorm2d(128) ,\n",
        "                                nn.ReLU(inplace=True) ,\n",
        "                                nn.MaxPool2d(kernel_size=2 , stride=2))\n",
        "\n",
        "        self.fc = nn.Sequential(nn.Linear(128*4*4,1024) ,\n",
        "                                nn.ReLU(inplace=True) ,\n",
        "                                nn.Linear(1024,128) ,\n",
        "                                nn.ReLU(inplace=True) ,\n",
        "                                nn.Linear(128,10) )\n",
        "    def forward( self , x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        # x = x.view(x.size(0) , -1)\n",
        "        x = x.reshape(x.size(0) , -1)\n",
        "        fc_out = self.fc(x)\n",
        "        return fc_out\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# 定義一個簡單的卷積神經網路\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(torch.relu(self.conv1(x)))\n",
        "        x = self.pool(torch.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 64 * 7 * 7)  # 展平張量\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# 定義超參數\n",
        "learning_rate = 1e-2      # 學習率\n",
        "batch_size = 128          # 批的大小\n",
        "epoches_num = 20          # 遍歷訓練集的次數\n",
        "\n",
        "# 下載並加載 MNIST 手寫數字訓練集\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# 定義模型、損失函數、優化器\n",
        "model = SimpleCNN()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# 檢查是否可以使用 GPU\n",
        "if torch.cuda.is_available():\n",
        "    print(\"CUDA is enabled!\")\n",
        "    model = model.cuda()\n",
        "model.train()\n",
        "\n",
        "# 開始訓練\n",
        "for epoch in range(epoches_num):\n",
        "    print(\"=\" * 40)\n",
        "    train_loss = 0.0\n",
        "    train_acc = 0.0\n",
        "\n",
        "    # 逐批次訓練\n",
        "    for i, data in enumerate(train_loader, 1):\n",
        "        img, label = data\n",
        "\n",
        "        # 使用 GPU 加速（若可行）\n",
        "        if torch.cuda.is_available():\n",
        "            img = img.cuda()\n",
        "            label = label.cuda()\n",
        "\n",
        "        # 前向傳播\n",
        "        optimizer.zero_grad()\n",
        "        out = model(img)\n",
        "        loss = criterion(out, label)\n",
        "\n",
        "        # 反向傳播\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # 計算損失和準確率\n",
        "        train_loss += loss.item() * label.size(0)\n",
        "        _, pred = out.max(1)\n",
        "        num_correct = pred.eq(label).sum().item()\n",
        "        train_acc += num_correct\n",
        "\n",
        "    # 輸出每回合的平均損失和準確率\n",
        "    print('Finish {} epoch: Loss: {:.6f}, Acc: {:.6f}'.format(\n",
        "        epoch + 1, train_loss / len(train_dataset), train_acc / len(train_dataset)))\n",
        "\n",
        "# 保存模型\n",
        "torch.save(model, 'cnn.pt')\n",
        "\n",
        "# 測試模型\n",
        "# 下載並加載 MNIST 測試集\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, transform=transforms.ToTensor())\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# 加載訓練完成的模型\n",
        "model = torch.load('cnn.pt')\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "model.eval()\n",
        "eval_acc = 0\n",
        "eval_loss = 0\n",
        "\n",
        "# 測試\n",
        "for data in test_loader:\n",
        "    img, label = data\n",
        "    if torch.cuda.is_available():\n",
        "        img = img.cuda()\n",
        "        label = label.cuda()\n",
        "\n",
        "    # 前向傳播\n",
        "    out = model(img)\n",
        "    loss = criterion(out, label)\n",
        "    eval_loss += loss.item() * label.size(0)\n",
        "\n",
        "    # 計算準確率\n",
        "    _, pred = out.max(1)\n",
        "    num_correct = pred.eq(label).sum().item()\n",
        "    eval_acc += num_correct\n",
        "\n",
        "# 輸出測試損失和準確率\n",
        "print('Test Loss: {:.6f}, Acc: {:.6f}'.format(eval_loss / len(test_dataset), eval_acc / len(test_dataset)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jb9T9--s8AaL",
        "outputId": "c9201e9a-9f56-4aa2-d553-4818457a2147"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========================================\n",
            "Finish 1 epoch: Loss: 1.793255, Acc: 0.560300\n",
            "========================================\n",
            "Finish 2 epoch: Loss: 0.451671, Acc: 0.865950\n",
            "========================================\n",
            "Finish 3 epoch: Loss: 0.319043, Acc: 0.902367\n",
            "========================================\n",
            "Finish 4 epoch: Loss: 0.261764, Acc: 0.920383\n",
            "========================================\n",
            "Finish 5 epoch: Loss: 0.218886, Acc: 0.933250\n",
            "========================================\n",
            "Finish 6 epoch: Loss: 0.185247, Acc: 0.943550\n",
            "========================================\n",
            "Finish 7 epoch: Loss: 0.157959, Acc: 0.952000\n",
            "========================================\n",
            "Finish 8 epoch: Loss: 0.138422, Acc: 0.958317\n",
            "========================================\n",
            "Finish 9 epoch: Loss: 0.123145, Acc: 0.962833\n",
            "========================================\n",
            "Finish 10 epoch: Loss: 0.110414, Acc: 0.966800\n",
            "========================================\n",
            "Finish 11 epoch: Loss: 0.099997, Acc: 0.969733\n",
            "========================================\n",
            "Finish 12 epoch: Loss: 0.091435, Acc: 0.972367\n",
            "========================================\n",
            "Finish 13 epoch: Loss: 0.084382, Acc: 0.974717\n",
            "========================================\n",
            "Finish 14 epoch: Loss: 0.079316, Acc: 0.976150\n",
            "========================================\n",
            "Finish 15 epoch: Loss: 0.074298, Acc: 0.977333\n",
            "========================================\n",
            "Finish 16 epoch: Loss: 0.070559, Acc: 0.978917\n",
            "========================================\n",
            "Finish 17 epoch: Loss: 0.066490, Acc: 0.979650\n",
            "========================================\n",
            "Finish 18 epoch: Loss: 0.063585, Acc: 0.980467\n",
            "========================================\n",
            "Finish 19 epoch: Loss: 0.060467, Acc: 0.980983\n",
            "========================================\n",
            "Finish 20 epoch: Loss: 0.057499, Acc: 0.982283\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-9ac4900fd808>:87: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model = torch.load('cnn.pt')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.057923, Acc: 0.981400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# 定义超参数\n",
        "batch_size  = 128       # 批的大小\n",
        "\n",
        "# 下载训练集 MNIST 手写数字测试集\n",
        "test_dataset  = datasets.MNIST( root='./data', train=False, transform=transforms.ToTensor())\n",
        "test_loader   = DataLoader(test_dataset , batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# 加载 Train 模型\n",
        "model = torch.load('cnn.pt')\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "model.eval()\n",
        "eval_acc  = 0\n",
        "eval_loss = 0\n",
        "\n",
        "\n",
        "# 测试\n",
        "for data in test_loader:\n",
        "    img, label = data\n",
        "    if torch.cuda.is_available():\n",
        "        img   = Variable(img  ).cuda()\n",
        "        label = Variable(label).cuda()\n",
        "    else:\n",
        "        img   = Variable(img  )\n",
        "        label = Variable(label)\n",
        "\n",
        "    out  = model(img)\n",
        "    loss = criterion(out, label)\n",
        "    eval_loss += loss.item() * label.size(0)\n",
        "\n",
        "    _ , pred = torch.max(out,1)\n",
        "    num_correct = (pred==label).sum()\n",
        "    eval_acc += num_correct.item()\n",
        "    print('Test Loss: {:.6f}   ,   Acc: {:.6f}'.format( eval_loss/(len(test_dataset)), eval_acc/(len(test_dataset)) ))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkBw_tSiDVlb",
        "outputId": "d7187576-cc55-4739-c25a-8c2e33b362e8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-84eb8ff2ac16>:16: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model = torch.load('cnn.pt')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.000166   ,   Acc: 0.012800\n",
            "Test Loss: 0.000586   ,   Acc: 0.025400\n",
            "Test Loss: 0.001389   ,   Acc: 0.037900\n",
            "Test Loss: 0.002061   ,   Acc: 0.050600\n",
            "Test Loss: 0.003102   ,   Acc: 0.063000\n",
            "Test Loss: 0.003962   ,   Acc: 0.075600\n",
            "Test Loss: 0.004445   ,   Acc: 0.088300\n",
            "Test Loss: 0.005625   ,   Acc: 0.100800\n",
            "Test Loss: 0.006492   ,   Acc: 0.113300\n",
            "Test Loss: 0.008578   ,   Acc: 0.125400\n",
            "Test Loss: 0.009959   ,   Acc: 0.137800\n",
            "Test Loss: 0.011108   ,   Acc: 0.150100\n",
            "Test Loss: 0.011916   ,   Acc: 0.162600\n",
            "Test Loss: 0.012951   ,   Acc: 0.174900\n",
            "Test Loss: 0.013783   ,   Acc: 0.187300\n",
            "Test Loss: 0.014953   ,   Acc: 0.199500\n",
            "Test Loss: 0.016485   ,   Acc: 0.211800\n",
            "Test Loss: 0.018048   ,   Acc: 0.224000\n",
            "Test Loss: 0.019255   ,   Acc: 0.236300\n",
            "Test Loss: 0.020182   ,   Acc: 0.248700\n",
            "Test Loss: 0.021641   ,   Acc: 0.261200\n",
            "Test Loss: 0.022153   ,   Acc: 0.273900\n",
            "Test Loss: 0.023709   ,   Acc: 0.286300\n",
            "Test Loss: 0.024604   ,   Acc: 0.298900\n",
            "Test Loss: 0.025380   ,   Acc: 0.311300\n",
            "Test Loss: 0.025654   ,   Acc: 0.324100\n",
            "Test Loss: 0.026346   ,   Acc: 0.336800\n",
            "Test Loss: 0.027869   ,   Acc: 0.349200\n",
            "Test Loss: 0.028512   ,   Acc: 0.361900\n",
            "Test Loss: 0.030155   ,   Acc: 0.374200\n",
            "Test Loss: 0.031156   ,   Acc: 0.386500\n",
            "Test Loss: 0.032644   ,   Acc: 0.398800\n",
            "Test Loss: 0.033589   ,   Acc: 0.411200\n",
            "Test Loss: 0.035197   ,   Acc: 0.423300\n",
            "Test Loss: 0.035639   ,   Acc: 0.436000\n",
            "Test Loss: 0.037092   ,   Acc: 0.448200\n",
            "Test Loss: 0.037636   ,   Acc: 0.460800\n",
            "Test Loss: 0.038725   ,   Acc: 0.473100\n",
            "Test Loss: 0.039783   ,   Acc: 0.485500\n",
            "Test Loss: 0.039891   ,   Acc: 0.498300\n",
            "Test Loss: 0.040110   ,   Acc: 0.511100\n",
            "Test Loss: 0.040450   ,   Acc: 0.523800\n",
            "Test Loss: 0.040531   ,   Acc: 0.536600\n",
            "Test Loss: 0.040839   ,   Acc: 0.549300\n",
            "Test Loss: 0.041408   ,   Acc: 0.562000\n",
            "Test Loss: 0.042035   ,   Acc: 0.574600\n",
            "Test Loss: 0.043755   ,   Acc: 0.587000\n",
            "Test Loss: 0.044739   ,   Acc: 0.599300\n",
            "Test Loss: 0.045470   ,   Acc: 0.611800\n",
            "Test Loss: 0.045517   ,   Acc: 0.624600\n",
            "Test Loss: 0.046152   ,   Acc: 0.637300\n",
            "Test Loss: 0.047535   ,   Acc: 0.649800\n",
            "Test Loss: 0.047985   ,   Acc: 0.662500\n",
            "Test Loss: 0.048079   ,   Acc: 0.675300\n",
            "Test Loss: 0.048158   ,   Acc: 0.688100\n",
            "Test Loss: 0.048272   ,   Acc: 0.700800\n",
            "Test Loss: 0.048445   ,   Acc: 0.713600\n",
            "Test Loss: 0.048473   ,   Acc: 0.726400\n",
            "Test Loss: 0.048795   ,   Acc: 0.739100\n",
            "Test Loss: 0.048857   ,   Acc: 0.751900\n",
            "Test Loss: 0.048978   ,   Acc: 0.764700\n",
            "Test Loss: 0.049765   ,   Acc: 0.777400\n",
            "Test Loss: 0.049975   ,   Acc: 0.790100\n",
            "Test Loss: 0.050421   ,   Acc: 0.802800\n",
            "Test Loss: 0.050719   ,   Acc: 0.815500\n",
            "Test Loss: 0.051152   ,   Acc: 0.828200\n",
            "Test Loss: 0.051430   ,   Acc: 0.840900\n",
            "Test Loss: 0.051499   ,   Acc: 0.853700\n",
            "Test Loss: 0.051507   ,   Acc: 0.866500\n",
            "Test Loss: 0.051521   ,   Acc: 0.879300\n",
            "Test Loss: 0.052619   ,   Acc: 0.891700\n",
            "Test Loss: 0.052686   ,   Acc: 0.904500\n",
            "Test Loss: 0.052770   ,   Acc: 0.917300\n",
            "Test Loss: 0.052861   ,   Acc: 0.930100\n",
            "Test Loss: 0.053385   ,   Acc: 0.942800\n",
            "Test Loss: 0.055313   ,   Acc: 0.955000\n",
            "Test Loss: 0.057241   ,   Acc: 0.967200\n",
            "Test Loss: 0.057921   ,   Acc: 0.979800\n",
            "Test Loss: 0.057923   ,   Acc: 0.981400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets\n",
        "\n",
        "train_dataset = datasets.MNIST( root='./data', train=True, transform=transforms.ToTensor(), download=True )\n",
        "\n"
      ],
      "metadata": {
        "id": "Di5MJGlUDg7q"
      },
      "execution_count": 17,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "歡迎使用 Colaboratory",
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}