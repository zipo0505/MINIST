{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch mnist 實例演練"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "程式執行時間約為\n",
    "\n",
    "- 141.72 sec (with GPU: GeForce GTX 860M)\n",
    "\n",
    "- 680.75 sec (with CPU: i5-4210H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 首先載入需要用的到套件\n",
    "# 矩陣模組運算工具\n",
    "import numpy as np                              \n",
    "# 繪圖工具\n",
    "import matplotlib.pyplot as plt                 \n",
    "\n",
    "import torch\n",
    "# PyTorch 的神經網路套件 (具參數調整)\n",
    "import torch.nn as nn                           \n",
    "# PyTorch 的神經網路套件 (不具參數調整)\n",
    "import torch.nn.functional as F                 \n",
    "# PyTorch 用作最佳化的套件\n",
    "import torch.optim as optim                     \n",
    "# PyTorch 電腦視覺相關套件\n",
    "import torchvision                              \n",
    "# PyTorch 電腦視覺相關套件\n",
    "from torchvision import datasets, transforms    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立CNN模型\n",
    "class Net(nn.Module):\n",
    "    # 我們這邊實作具兩層卷積層及兩層全連接層的CNN\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 卷積層 1: nn.Conv2d(in_channels, out_channels, kernel_size, stride=1)\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5, 1)    \n",
    "        # 卷積層 2: nn.Conv2d(in_channels, out_channels, kernel_size, stride=1)\n",
    "        self.conv2 = nn.Conv2d(20, 50, 5, 1)   \n",
    "        # 全連接層 1:　nn.Linear(in_features, out_features）\n",
    "        self.fc1 = nn.Linear(4*4*50, 500)      \n",
    "        # 全連接層 2 (最後接上 10 類別分類):　nn.Linear(in_features, out_features）\n",
    "        self.fc2 = nn.Linear(500, 10)          \n",
    "    \n",
    "    # 模型中的層傳遞\n",
    "    def forward(self, x):\n",
    "        # 對 input x 做 conv1 的 convolution 後以 ReLU 啟動函數進行處理\n",
    "        x = F.relu(self.conv1(x))              \n",
    "        # 對接續的 x 做 2 * 2 的 max pooling\n",
    "        x = F.max_pool2d(x, 2, 2)              \n",
    "        # 對接續的 x 做 conv2 的 convolution 後以 ReLU 啟動函數進行處理\n",
    "        x = F.relu(self.conv2(x))              \n",
    "        # 對接續的 x 做 2 * 2 的 max pooling\n",
    "        x = F.max_pool2d(x, 2, 2)              \n",
    "        # 改變張量維度 (flatten) 以接續全連接層\n",
    "        x = x.view(-1, 4*4*50)                 \n",
    "        # 對接續的 x 做 fc1 全連接，並以ReLU啟動函數進行處理\n",
    "        x = F.relu(self.fc1(x))                \n",
    "        # 對接續的 x 做 fc2 全連接，並以ReLU啟動函數進行處理\n",
    "        x = self.fc2(x)                        \n",
    "        # return softmax 函數作類別分類\n",
    "        return F.log_softmax(x, dim=1)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 超參數區 (hyperparameters)\n",
    "# 本區參數可手動調整以最佳化模型\n",
    "\n",
    "# 進行一次批次訓練所使用的資料量\n",
    "batch_size = 64           \n",
    "# 進行一次批次驗證所使用的資料量\n",
    "test_batch_size = 1000    \n",
    "# 訓練次數 = 10\n",
    "epochs = 10               \n",
    "# 模型的學習率\n",
    "lr = 0.01                 \n",
    "# 模型最佳化時用以調整學習率的參數\n",
    "momentum = 0.5            \n",
    "# 每 10 次迭代就印出一次當前訓練狀態\n",
    "log_interval = 10         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 設定 torch 進行運算的裝置，如果有 cuda 就使用 GPU 進行運算，若無則使用 CPU 進行運算\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 載入手寫字辨識訓練資料\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(\n",
    "        './data',\n",
    "        # 表示進行訓練 (訓練過程調整模型參數)\n",
    "        train=True,                                              \n",
    "        # 若之前無下載過 mnist，則會自動進行下載資料的動作\n",
    "        download=True,                                           \n",
    "        # 表示將影像資料轉為張量進行運算\n",
    "        transform=transforms.Compose([transforms.ToTensor()])\n",
    "    ),  \n",
    "    batch_size=batch_size, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 載入手寫字辨識驗證資料\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(\n",
    "        './data',\n",
    "        # 表示進行驗證 (不調整模型參數)\n",
    "        train=False,                                             \n",
    "        # 表示將影像資料轉為張量進行運算\n",
    "        transform=transforms.Compose([transforms.ToTensor()])\n",
    "    ),  \n",
    "    batch_size=test_batch_size, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義訓練過程\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    # 開始訓練\n",
    "    model.train()\n",
    "    # 從 train_loader 中取出 batch 的 index, 資料, 以及資料的標籤\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):   \n",
    "        # 指定不同變數之張量於運算的GPU或CPU裝置\n",
    "        data, target = data.to(device), target.to(device)       \n",
    "        # 模型初始化\n",
    "        optimizer.zero_grad()                \n",
    "        # 將資料傳入模型\n",
    "        output = model(data)                 \n",
    "        # 計算模型預測的答案與真實資料的誤差(negative log likelihood loss)\n",
    "        loss = F.nll_loss(output, target)    \n",
    "        # 反向傳播\n",
    "        loss.backward()                      \n",
    "        # 調整模型內部參數\n",
    "        optimizer.step()                     \n",
    "        # print 出該模型在 epoch 的訓練資料百分比以及 loss 數值\n",
    "        if batch_idx % log_interval == 0:    \n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義驗證過程\n",
    "def test(model, device, test_loader):\n",
    "    # 開始驗證\n",
    "    model.eval()\n",
    "    # 初始化 loss\n",
    "    test_loss = 0    \n",
    "    # 初始化預測正確數\n",
    "    correct = 0      \n",
    "    #驗證過程不進行模型內部參數調整\n",
    "    with torch.no_grad():     \n",
    "        # 從 test_loader 中取出資料以及資料的標籤\n",
    "        for data, target in test_loader:                          \n",
    "            # 指定不同變數之張量於運算的 GPU 或 CPU 裝置\n",
    "            data, target = data.to(device), target.to(device)     \n",
    "            # 將資料傳入模型\n",
    "            output = model(data)                                  \n",
    "            # 計算驗證過程的 loss 數值\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  \n",
    "            # 以模型預測的分數的指標位置去取得預測的答案(類別)\n",
    "            pred = output.argmax(dim=1, keepdim=True)                        \n",
    "            # 計算模型預測的正確率\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()            \n",
    "\n",
    "    # 平均批次驗證的 loss 數值\n",
    "    test_loss /= len(test_loader.dataset)                                    \n",
    "\n",
    "    # print 出 loss 數值及正確率\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format( \n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將模型指定到 GPU 或 CPU 裝置進行運算\n",
    "model = Net().to(device)            \n",
    "# model = nn.DataParallel(model)    # 利用nn.DataParallel來使模型以多GPU進行運算\n",
    "# 使用stochastic gradient descent進行最佳化\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以 for 迴圈進行訓練及驗證\n",
    "# range 的 epoch 數字要 +1\n",
    "for epoch in range(1, epochs + 1):\n",
    "        train(model, device, train_loader, optimizer, epoch)\n",
    "        test(model, device, test_loader)\n",
    "\n",
    "# 儲存訓練好的模型\n",
    "torch.save(model.state_dict(),\"mnist_cnn.pt\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 接著取出一些手寫字辨識的影像來查看預測情況\n",
    "\n",
    "# 將 test_loader 的資料取出且以跟前面一樣的裝置做張量儲存\n",
    "examples = enumerate(test_loader)    \n",
    "batch_idx, (test_data, test_targets) = next(examples)\n",
    "test_data = test_data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將資料傳入模型 (在此屬於驗證過程)\n",
    "with torch.no_grad():\n",
    "    output = model(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以 matplotlib 做 3 * 3 的組合圖\n",
    "fig = plt.figure()\n",
    "for k in range(9):\n",
    "    plt.subplot(3,3,k+1)\n",
    "    # 優化組合圖排列\n",
    "    plt.tight_layout()    \n",
    "    # 以灰階影像顯示出每一張子圖\n",
    "    plt.imshow(test_data[k][0].cpu().numpy(), cmap='gray')                              \n",
    "    # 將預測的答案設為每個子圖的 title\n",
    "    plt.title(\"Prediction: {}\".format(output.data.max(1, keepdim=True)[1][k].item()))   \n",
    "    # 不顯示X座標軸刻度\n",
    "    plt.xticks([])        \n",
    "    # 不顯示Y座標軸刻度\n",
    "    plt.yticks([])        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
